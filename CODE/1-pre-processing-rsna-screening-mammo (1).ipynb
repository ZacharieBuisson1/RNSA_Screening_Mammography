{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy  as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport sys\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\n\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-08T21:13:52.089191Z","iopub.execute_input":"2023-01-08T21:13:52.089752Z","iopub.status.idle":"2023-01-08T21:13:52.094980Z","shell.execute_reply.started":"2023-01-08T21:13:52.089714Z","shell.execute_reply":"2023-01-08T21:13:52.093988Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install -U pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:13:56.560538Z","iopub.execute_input":"2023-01-08T21:13:56.560937Z","iopub.status.idle":"2023-01-08T21:14:12.081056Z","shell.execute_reply.started":"2023-01-08T21:13:56.560908Z","shell.execute_reply":"2023-01-08T21:14:12.080094Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting pylibjpeg\n  Downloading pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\nCollecting pylibjpeg-openjpeg\n  Downloading pylibjpeg_openjpeg-1.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pylibjpeg-libjpeg\n  Downloading pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\nCollecting python-gdcm\n  Downloading python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg) (1.21.6)\nInstalling collected packages: python-gdcm, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg\nSuccessfully installed pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.2 pylibjpeg-openjpeg-1.3.0 python-gdcm-3.0.20\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import des bases ","metadata":{}},{"cell_type":"code","source":"### Création d'un path de lecture des données ###\npath = '/kaggle/input/rsna-breast-cancer-detection/'\n\ntrain_path = '/kaggle/input/rsna-breast-cancer-detection/train_images'\ntest_path = '/kaggle/input/rsna-breast-cancer-detection/test_images'","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.083280Z","iopub.execute_input":"2023-01-08T21:14:12.083634Z","iopub.status.idle":"2023-01-08T21:14:12.089425Z","shell.execute_reply.started":"2023-01-08T21:14:12.083602Z","shell.execute_reply":"2023-01-08T21:14:12.088288Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"### Import des données d'entrainements ###\ntrain_set = pd.read_csv(path+\"train.csv\")\ntrain_set.sort_values(by=['patient_id', 'image_id'], inplace=True)\ntrain_set.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.090823Z","iopub.execute_input":"2023-01-08T21:14:12.091145Z","iopub.status.idle":"2023-01-08T21:14:12.262838Z","shell.execute_reply.started":"2023-01-08T21:14:12.091117Z","shell.execute_reply":"2023-01-08T21:14:12.261853Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_set","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.265566Z","iopub.execute_input":"2023-01-08T21:14:12.267576Z","iopub.status.idle":"2023-01-08T21:14:12.300237Z","shell.execute_reply.started":"2023-01-08T21:14:12.267540Z","shell.execute_reply":"2023-01-08T21:14:12.299044Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n0            2           5   640805896          L  MLO  68.0       0       0   \n1            2           5   940388076          R   CC  68.0       0       0   \n2            2           5  1351088028          L   CC  68.0       0       0   \n3            2           5  1633417959          R  MLO  68.0       0       0   \n4            1          25   822390278          R   CC  62.0       0       0   \n...        ...         ...         ...        ...  ...   ...     ...     ...   \n54701        1       65530  1627492472          L  MLO  48.0       0       0   \n54702        1       65534    44480502          R  MLO  46.0       0       0   \n54703        1       65534  1174089649          R   CC  46.0       0       0   \n54704        1       65534  1436834199          L   CC  46.0       0       0   \n54705        1       65534  1888933323          L  MLO  46.0       0       0   \n\n       invasive  BIRADS  implant density  machine_id  difficult_negative_case  \n0             0     0.0        0     NaN          21                     True  \n1             0     NaN        0     NaN          21                    False  \n2             0     0.0        0     NaN          21                     True  \n3             0     NaN        0     NaN          21                    False  \n4             0     1.0        0       B          49                    False  \n...         ...     ...      ...     ...         ...                      ...  \n54701         0     NaN        0       C          49                    False  \n54702         0     1.0        0       C          49                    False  \n54703         0     1.0        0       C          49                    False  \n54704         0     1.0        0       C          49                    False  \n54705         0     1.0        0       C          49                    False  \n\n[54706 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>site_id</th>\n      <th>patient_id</th>\n      <th>image_id</th>\n      <th>laterality</th>\n      <th>view</th>\n      <th>age</th>\n      <th>cancer</th>\n      <th>biopsy</th>\n      <th>invasive</th>\n      <th>BIRADS</th>\n      <th>implant</th>\n      <th>density</th>\n      <th>machine_id</th>\n      <th>difficult_negative_case</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>5</td>\n      <td>640805896</td>\n      <td>L</td>\n      <td>MLO</td>\n      <td>68.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>5</td>\n      <td>940388076</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>68.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>1351088028</td>\n      <td>L</td>\n      <td>CC</td>\n      <td>68.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5</td>\n      <td>1633417959</td>\n      <td>R</td>\n      <td>MLO</td>\n      <td>68.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>25</td>\n      <td>822390278</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>B</td>\n      <td>49</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54701</th>\n      <td>1</td>\n      <td>65530</td>\n      <td>1627492472</td>\n      <td>L</td>\n      <td>MLO</td>\n      <td>48.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>C</td>\n      <td>49</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>54702</th>\n      <td>1</td>\n      <td>65534</td>\n      <td>44480502</td>\n      <td>R</td>\n      <td>MLO</td>\n      <td>46.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>C</td>\n      <td>49</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>54703</th>\n      <td>1</td>\n      <td>65534</td>\n      <td>1174089649</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>46.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>C</td>\n      <td>49</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>54704</th>\n      <td>1</td>\n      <td>65534</td>\n      <td>1436834199</td>\n      <td>L</td>\n      <td>CC</td>\n      <td>46.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>C</td>\n      <td>49</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>54705</th>\n      <td>1</td>\n      <td>65534</td>\n      <td>1888933323</td>\n      <td>L</td>\n      <td>MLO</td>\n      <td>46.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>C</td>\n      <td>49</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>54706 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pydicom\nfrom os import listdir\n\ndef load_patient_scans(path, patient_id):\n    patient_path = path + '/' + str(patient_id)\n    return [pydicom.dcmread(patient_path + '/' + file) for file in listdir(patient_path)]","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.301797Z","iopub.execute_input":"2023-01-08T21:14:12.302217Z","iopub.status.idle":"2023-01-08T21:14:12.518784Z","shell.execute_reply.started":"2023-01-08T21:14:12.302179Z","shell.execute_reply":"2023-01-08T21:14:12.517886Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # scans_full_info = []\n# scans_matrix = []\n# compteur = 0\n\n# ids = train_set['patient_id'].unique()\n\n# for patient_ids in ids[0:10]:\n#     # Load all scans of the twelfth patient\n#     scans = load_patient_scans(train_path, patient_ids)\n#     if compteur % 20 == 0:\n#         print('Patient {},  id : {}'.format(compteur, patient_ids))\n#     scans_matrix += [scan.pixel_array for scan in scans]\n#     del scans\n#     compteur += 1","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.520077Z","iopub.execute_input":"2023-01-08T21:14:12.520607Z","iopub.status.idle":"2023-01-08T21:14:12.525594Z","shell.execute_reply.started":"2023-01-08T21:14:12.520577Z","shell.execute_reply":"2023-01-08T21:14:12.524224Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# # Look at raw pixelarrays\n# fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n# im = ax[0].imshow(scans[0].pixel_array, cmap='bone')\n# ax[0].grid(False)\n# fig.colorbar(im, ax=ax[0])\n# sns.histplot(scans[0].pixel_array.flatten(), ax=ax[1], bins=50)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.527025Z","iopub.execute_input":"2023-01-08T21:14:12.527482Z","iopub.status.idle":"2023-01-08T21:14:12.537554Z","shell.execute_reply.started":"2023-01-08T21:14:12.527440Z","shell.execute_reply":"2023-01-08T21:14:12.536506Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Pre-Processing des images ","metadata":{}},{"cell_type":"markdown","source":"Une des premières étapes consistent à pre-processé les données, afin de pouvoir permettre : :\n1. Gérer la taille importante des données ;\n2. Avoir une meilleure qualité de prédiction sur le modèle.\n\nPour faire le pré-processing, un certain nombre d'opération vont devoir être réalisées : \n1. Normalisation des couleurs ; \n2. Mise du même coté de toutes les images ; \n3. Suppression de l'arrière plan sur les images ; \n4. *Windowing* : amélioration du contraste pour une meilleure visualisation ;\n5. Crop : Delete random part of this image.\n\n\nCes idées sont inspirées du NoteBook Kaggle suivant : https://www.kaggle.com/code/paulbacher/custom-preprocessor-rsna-breast-cancer\n","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom tqdm.notebook import tqdm\nfrom joblib import Parallel, delayed\nfrom pydicom.pixel_data_handlers import apply_windowing\n\nclass MammographyPreProcessing():\n    \"\"\"\n    Class whose purpose is to pre-process the data in order to facilitate the analysis.\n    \"\"\"\n    \n    def __init__(self, size, side):\n        \"\"\"\n        Initialization of the class.\n        \n        Inputs :\n            size : Tuple of int.\n                Final size of the image to process. If none, can't resize the image.\n            side : String.\n                Says the size requiered.\n        \"\"\"\n        self.size = size\n        assert type(size) == tuple, \"Size should be a tuple\"\n        assert len(size) == 2, \"Size should be a tuple with a length of two.\"\n        self.side = side\n        assert side in ['L', 'R'], \"Side should be 'L' or 'R'\"\n    \n    def multiple_preprocessing(self, paths, final_size= 255, save=False, n_jobs=-1):\n        \"\"\"\n        Given a list of paths to find images, realize every single preprocessing.\n        \n        Inputs :\n            paths : List of str.\n                List of paths to preprocess.\n            final_size : int.\n                Max of the number when reducing dimension of the image.\n            save : bool.\n                If save is needed.\n            n_jobs : int.\n                Number of heart used at the same time for parralelization. If -1, use all.\n        \"\"\"\n        \n        Parallel(n_jobs=n_jobs)(delayed(self.preprocess_one_image)(path, final_size, save) for path in tqdm(paths, total=len(paths)))\n        \n    \n    def preprocess_one_image(self, path : str, final_size=255, save=False):\n        \"\"\"\n        Pre-processing of a single image.\n        \n        Inputs: \n            path : String.\n                Give a path of a DICOM image, which may be read by the following code.\n        \"\"\"\n        assert path.endswith('.dcm'), 'Path should provide a DCM image, either it wont work.'\n        scan = pydicom.dcmread(path)\n        img_matrix = scan.pixel_array\n        img_matrix = self._windowing(img_matrix, scan)\n        img_matrix = self._fix_photometric_interpretation(img_matrix, scan)\n        img_matrix = self._normalize(img_matrix, final_size)\n        img_matrix = self._change_laterality(img_matrix)\n        img_matrix = self._crop(img_matrix)\n\n        \n        img_matrix = cv2.resize(img_matrix, self.size) # Resizing \n        \n        if save:\n            self.save_image(path, img_matrix)\n        \n        return img_matrix\n    \n    def save_image(self, path, img):\n        \"\"\"\n        Function to save data after processing it.\n        \n        Inputs : \n            path : String.\n                Give a path of a DICOM image, which may be read by the following code.                \n            img : Numpy Array.\n                Matrix of scan related values.\n        \"\"\"\n        splitted_path = path.split('/')\n        path_ = \"/kaggle/working/{}\".format(splitted_path[-2])\n\n        if not os.path.exists(path_):\n            os.makedirs(path_)\n        \n        with open(path_+'/'+splitted_path[-1].split(\".dcm\")[0]+'.pkl', 'wb') as f:\n            pickle.dump(img, f)\n    \n    def display_image(self, path, preprocess=False):\n        \"\"\"\n        Display the image with a colorful representation.\n        \n        Inputs:\n            img : Numpy Array.\n                Matrix of scan related values.\n        \"\"\"\n        \n        plt.figure(figsize=(8,8))\n        if preprocess:\n            img = self.preprocess_one_image(path)\n        else:\n            img = pydicom.dcmread(path).pixel_array\n        \n        plt.imshow(img, cmap='jet')\n        plt.show()\n        \n\n    def _windowing(self, img, scan):\n        \"\"\"\n        Improve contrast on the picture. This is one of the most relevant part.\n        \n        Inputs : \n            img : Numpy Array.\n                Matrix of scan related values.\n            scan : pydicom.dataset.FileDataset.\n                Scan related information, with image and several other info.\n        \"\"\"\n        return apply_windowing(img, scan)\n    \n    def _normalize(self, img, final_size=255):\n        \"\"\"\n        Normalize the data to put them in grey-scale.\n        \n        Inputs:\n            img : Numpy Array.\n                Matrix of scan related values.\n            final_size : int.\n                Maximum of the pixel matrix value after normalization.\n        \"\"\"\n        if img.max()!= 0:\n            img /= img.max()\n        img *= final_size\n        return img\n    \n    def _change_laterality(self, img):\n        \"\"\"\n        Determine laterality of the scan, then apply a changement if the requiere laterality is not the good one.\n        \n        Inputs : \n            img : Numpy Array.\n                Matrix of scan related values.\n        \"\"\"\n        middle = len(img[0])//2\n        lat = ''\n        if sum(sum(img[:, :middle]))>sum(sum(img[:, middle:])):\n            lat='L'\n        else:\n            lat='R'\n\n        if self.side != lat:\n            img = np.array(list(map(lambda u: u[::-1], img)))\n        \n        return img\n    \n    def _fix_photometric_interpretation(self, img, scan):\n        \"\"\"\n        AUTHOR : Paul BACHER.\n        Fixing one only colour for scans. \"Interpret pixels in a consistant way.\"\n        \n        Inputs : \n            img : Numpy Array.\n                Matrix of scan related values.\n            scan : pydicom.dataset.FileDataset.\n                Scan related information, with image and several other info.\n        \"\"\"\n        if scan.PhotometricInterpretation == 'MONOCHROME1':\n            return img.max() - img\n        elif scan.PhotometricInterpretation == 'MONOCHROME2':\n            return img - img.min()\n        else:\n            raise ValueError(\"Invalid Photometric Interpretation: {}\"\n                               .format(scan.PhotometricInterpretation))\n        \n    def _crop(self, img, threshold=5):\n        \"\"\"\n        Crop the useless part of the picture.\n\n        Inputs : \n            img : Numpy Array.\n                Matrix of scan related values.\n            threshold : int.\n                Min value that you can decide to delete, when deleting background.\n        \"\"\"\n        # Binarization\n#         plt.imshow(img)\n        bin_img =  (img > threshold).astype(np.uint8)\n\n        # Contouring\n        contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n        contour = max(contours, key=cv2.contourArea)\n\n        # Separation \n        mask = np.zeros(img.shape, np.uint8)\n        img_temp = cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED) # Draw contours\n        output = cv2.bitwise_and(img_temp, mask) # Fusion of the two previous images \n\n        x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])\n        y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])\n        x1, x2 = int(0.99 * x1), int(1.01 * x2)\n        y1, y2 = int(0.99 * y1), int(1.01 * y2)\n        return img[y1:y2, x1:x2]        \n","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:12.539168Z","iopub.execute_input":"2023-01-08T21:14:12.539834Z","iopub.status.idle":"2023-01-08T21:14:12.808672Z","shell.execute_reply.started":"2023-01-08T21:14:12.539791Z","shell.execute_reply":"2023-01-08T21:14:12.807429Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ids = train_set['patient_id'].unique()\n\npath_test = [train_path + '/' + str(ids[i]) for i in range(len(ids))]\nfull_files = []\nfor j in range(len(path_test)):\n    full_files += [path_test[j] + '/' + file for file in listdir(path_test[j])]","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:14:55.780777Z","iopub.execute_input":"2023-01-08T21:14:55.781169Z","iopub.status.idle":"2023-01-08T21:15:29.703034Z","shell.execute_reply.started":"2023-01-08T21:14:55.781139Z","shell.execute_reply":"2023-01-08T21:15:29.702019Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"MammographyPreProcessing((255, 255), 'L').multiple_preprocessing(full_files, save=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T21:18:34.003206Z","iopub.execute_input":"2023-01-08T21:18:34.003628Z","iopub.status.idle":"2023-01-08T21:19:11.108410Z","shell.execute_reply.started":"2023-01-08T21:18:34.003597Z","shell.execute_reply":"2023-01-08T21:19:11.106595Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/54706 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496184161e33452d8718fc328ed358ef"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/732879230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMammographyPreProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/180936766.py\u001b[0m in \u001b[0;36mmultiple_preprocessing\u001b[0;34m(self, paths, final_size, save, n_jobs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_one_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"path_test = train_path + '/' + str(ids[0])\nfiles = [file for file in listdir(path_test)]\nfiles\nplt.imshow(MammographyPreProcessing((255, 255), 'L').preprocess_one_image(path_test+'/'+files[2], save=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_test+'/'+files[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/test.pkl', 'wb') as f:\n    pickle.dump(MammographyPreProcessing((255, 255), 'L').display_image(path_test+'/'+files[0], preprocess=True), f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MammographyPreProcessing((255, 255), 'L').display_image(path_test+'/'+files[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(contour), type(mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(pydicom.dcmread(path_test+'/'+files[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = pydicom.dcmread(path_test+'/'+files[0]).pixel_array\nmiddle = len(a[0])//2\nprint(a[:, :middle].shape, a.shape)\n\nsum(sum(a[:, :middle]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pydicom\nfrom os import listdir\n\ndef load_patient_scans(path, patient_id):\n    patient_path = path + '/' + str(patient_id)\n    return [pydicom.dcmread(patient_path + '/' + file) for file in listdir(patient_path)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Une visualisation sur le sujet.","metadata":{}},{"cell_type":"code","source":"### Sauvegarde de tous les paths ###\nall_path = []\n\n### Sauvegarde de tous les paths utiles ###\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        all_path += [os.path.join(dirname, filename)]\n\n### Filtre sur les données inutiles ###\nprint('Ok first extract')\nall_images = [image for image in all_path if (image.endswith(\".dcm\") and (\"train_images\" in image))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_cancer = train_set[train_set['cancer']==1].reset_index(drop=True).image_id.astype(str)\nlist_cancer\n# cancer_image = [u for u in list_cancer ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gdcm import ImageToPixmapFilter\n\n# specify your image path\nimage_path = path + 'train_images/{0}/{1}.dcm'.format(train_set[train_set['cancer']==1].reset_index(drop=True).patient_id[0], \n                                                      1360338805)\nreader = gdcm.ImageReader()\nreader.SetFileName(image_path)\nimage = reader.Read()\n\n# Convert the image to a pixmap\nimage_to_pixmap = gdcm.ImageToPixmapFilter()\nimage_to_pixmap.SetInput(image)\npixmap = image_to_pixmap.GetOutput()\n\n# Get the pixel matrix\npixel_matrix = pixmap.GetBuffer()\n\nprint(pixel_matrix)\n\n# print(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdcm\n\nimage_path = path + 'train_images/{0}/{1}.dcm'.format(train_set[train_set['cancer']==1].reset_index(drop=True).patient_id[0], \n                                                      1360338805)\n\n# Read the DICOM image using the ImageReader\nreader = gdcm.ImageReader()\nreader.SetFileName(image_path)\nimage = reader.Read()\n\n# Write the image to a file using the ImageWriter\nwriter = gdcm.ImageWriter()\nwriter.SetFileName(\"output.png\")\nwriter.SetFile(reader.GetFile())\nwriter.SetImage(image)\nwriter.Write()\n\n# Print the image\nprint(image)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pylibjpeg\nfrom pydicom import dcmread\nfrom pydicom.pixel_data_handlers import pillow_handler\npillow_handler.PillowJPEGTransferSyntaxes.append('1.2.840.10008.1.2.4.70')\nimport matplotlib.pylab as plt\n\n\nprint(image_path)\nds = dicom.dcmread(image_path)\n# print(ds)\nds.pixel_array\nprint(\"La taille de l'image est de {} x {}\".format(ds.pixel_array.shape[0], ds.pixel_array.shape[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds.pixel_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nnp.unique(ds.pixel_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Entrainement d'un premier modèle très basique ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model\nclass CNN(tf.keras.Model):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = tf.keras.layers.Conv2D(32, kernel_size=3, stride=1, padding=1)\n        self.flatten = tf.keras.layers.Flatten()\n        self.fc1 = tf.keras.layers.Dense(128)\n        self.fc2 = tf.keras.layers.Dense(10)\n\n    def call(self, x):\n        x = tf.nn.relu(self.conv1(x))\n        x = tf.nn.max_pool2d(x, kernel_size=2, strides=2)\n        x = tf.nn.relu(self.conv2(x))\n        x = tf.nn.max_pool2d(x, kernel_size=2, strides=2)\n        x = self.flatten(x)\n        x = tf.nn.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data\nx_train = x_train / 255.0\nx_test = x_test / 255.0\nx_train = x_train[..., tf.newaxis]\nx_test = x_test[..., tf.newaxis]\n\n# Create the model\nmodel = CNN()\n\n# Define the loss function and optimizer\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n# Define the metrics to track\ntrain_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\nval_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n\n# Training loop\nfor epoch in range(5):\n    # Training\n    for images, labels in train_dataset:\n        with tf.GradientTape() as tape:\n            logits = model(images, training=True)\n            loss_value = loss_fn(labels, logits)\n        grads = tape.gradient(loss_value, model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n        train_acc_metric(labels, logits)\n    train_acc = train_acc_metric.result()\n    train_acc_metric.reset_states()\n\n    # Validation\n    for val_images, val_labels in val_dataset:\n        val_logits = model(val_images, training=False)\n        val_acc_metric(val_labels, val_logits)\n    val_acc = val_acc_metric.result()\n    val_acc_metric.reset_states()\n\n    template = \"Epoch {}, Train accuracy: {}, Validation accuracy: {}\"\n    print(template.format(epoch+1, train_acc, val_acc))\n\n# Testing\nfor test_images, test_labels in test_dataset:\n    logits = model(test_images, training=False)\n    test_acc_metric(test_labels, logits)\nprint(\"Test accuracy: {}\".format(test_acc_metric.result()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}